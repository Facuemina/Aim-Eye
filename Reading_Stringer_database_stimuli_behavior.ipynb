{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "JTm-WM99LF9m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from umap import UMAP\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import scipy.io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sUzpeuDJLgmo"
   },
   "outputs": [],
   "source": [
    "#@title Data retrieval and loading\n",
    "# fname = \"stimspont_M170604_MP031_20170627.mat\"\n",
    "# url = \"https://figshare.com/ndownloader/files/11492261\" HECHO\n",
    "\n",
    "rat='rat2'\n",
    "# url and file name of other data recorded from other mice\n",
    "\n",
    "fname = \"stimspont_M150824_MP019_2016-03-23.mat\"\n",
    "url = \"https://figshare.com/ndownloader/files/11492555\"\n",
    "\n",
    "# fname = \"stimspont_M170714_MP032_2017-08-01.mat\"\n",
    "# url = \"https://figshare.com/ndownloader/files/11492258\"\n",
    "\n",
    "# fname = \"stimspont_M170717_MP033_2017-08-25.mat\"\n",
    "# url = \"https://figshare.com/ndownloader/files/11492255\"\n",
    "\n",
    "\n",
    "if not os.path.isfile(fname):\n",
    "    try:\n",
    "        r = requests.get(url)\n",
    "    except requests.ConnectionError:\n",
    "        print(\"!!! Failed to download data !!!\")\n",
    "    else:\n",
    "        if r.status_code != requests.codes.ok:\n",
    "            print(\"!!! Failed to download data !!!\")\n",
    "        else:\n",
    "            with open(fname, \"wb\") as fid:\n",
    "                fid.write(r.content)\n",
    "\n",
    "dat = scipy.io.loadmat('stimspont_M170604_MP031_20170627.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GPACZKTyLjjy",
    "outputId": "d0c53e76-7771-4912-f182-d741ccdc34f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sresp:  (3300, 12060)\n",
      "istim:  (3300,)\n",
      "pupilarea:  (17553, 1)\n",
      "runAngle:  (17553, 1)\n",
      "runSpeed:  (17553, 1)\n",
      "motionSVD:  (17553, 500)\n",
      "motionMask:  (240, 320, 500)\n",
      "xyz:  (12060, 3)\n"
     ]
    }
   ],
   "source": [
    "sresp = dat['stim'][0]['resp'][0] # stim x neurons\n",
    "# spont = dat['stim'][0]['spont'][0] # timepts x neurons\n",
    "istim = (dat['stim'][0]['istim'][0]).astype(np.int32) # stim ids \n",
    "istim -= 1 # get out of MATLAB convention\n",
    "istim = istim[:,0]\n",
    "\n",
    "pupilArea = dat['beh'][0]['pupil'][0]['area'][0][0]\n",
    "pupilArea = pupilArea[:int(35106/2)] #original pupilArea contains 35106/2 nans\n",
    "runSpeed = dat['beh'][0]['runSpeed'][0]\n",
    "runAngle = dat['beh'][0]['runAngle'][0]\n",
    "motionSVD = dat['beh'][0]['face'][0]['motionSVD'][0][0]\n",
    "motionMask = dat['beh'][0]['face'][0]['motionMask'][0][0]\n",
    "xyz = dat['med']\n",
    "\n",
    "print(\"sresp: \", sresp.shape)\n",
    "print(\"istim: \", istim.shape)\n",
    "print(\"pupilarea: \", pupilArea.shape)\n",
    "print(\"runAngle: \", runAngle.shape)\n",
    "print(\"runSpeed: \", runSpeed.shape)\n",
    "print(\"motionSVD: \", motionSVD.shape)\n",
    "print(\"motionMask: \", motionMask.shape)\n",
    "\n",
    "print(\"xyz: \", xyz.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17553, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(motionSVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.stats import zscore\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.linear_model as lm\n",
    "import sklearn as sk\n",
    "from sklearn import linear_model\n",
    "\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.advanced_activations import ReLU\n",
    "# from keras.layers.advanced_activations import Tanh\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title take PCA after preparing data by z-score\n",
    "Z = zscore(dat['Fsp'], axis=1)\n",
    "Z = np.nan_to_num(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=500)\n",
    "pca_zscore = pca_model.fit_transform(Z.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_model(input_dim, output_dim, nodes, name='model',activation = ['relu'],activation_out='linear'):\n",
    "    def create_model():\n",
    "        # Create model\n",
    "        model = Sequential(name=name)\n",
    "        if len(nodes)==0:\n",
    "            model.add(Dense(output_dim, input_dim=input_dim, activation=activation[0]))\n",
    "        else:\n",
    "            model.add(Dense(nodes[0], input_dim=input_dim, activation=activation[0]))\n",
    "            for i in range(1,len(nodes)):\n",
    "                model.add(Dense(nodes[i], input_dim=nodes[i-1], activation=activation[i]))\n",
    "            model.add(Dense(output_dim, activation=activation_out))\n",
    "\n",
    "        # Compile model\n",
    "        model.compile(loss='mse',   optimizer='adam')#,   metrics=['mse'])\n",
    "        return model\n",
    "    return create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(Xdata,Ydata,trials,i,T):\n",
    "    L = Xdata.shape[0]\n",
    "    i_0 = i*round(L/trials)\n",
    "    i_f = i_0 + L-T\n",
    "    X_tr, X_tst = np.zeros((L-T,Xdata.shape[1])), np.zeros((T,Xdata.shape[1]))\n",
    "    y_tr, y_tst = np.zeros((L-T,1)), np.zeros((T,1))\n",
    "\n",
    "    if i_f>L:\n",
    "        X_tr[0:i_f-L] = Xdata[0:i_f-L]\n",
    "        X_tr[i_f-L:] = Xdata[i_0:]\n",
    "        X_tst = Xdata[i_f-L:i_0]\n",
    "        y_tr[0:i_f-L] = Ydata[0:i_f-L]\n",
    "        y_tr[i_f-L:] = Ydata[i_0:]\n",
    "        y_tst = Ydata[i_f-L:i_0]\n",
    "    elif i_f+T == L:\n",
    "        X_tr = Xdata[i_0:i_f]\n",
    "        X_tst = Xdata[i_f:]\n",
    "        y_tr = Ydata[i_0:i_f]\n",
    "        y_tst = Ydata[i_f:]\n",
    "    else:\n",
    "        X_tr = Xdata[i_0:i_f]\n",
    "        X_tst[:L-i_f] = Xdata[i_f:]\n",
    "        X_tst[L-i_f:] = Xdata[:i_0]\n",
    "        y_tr = Ydata[i_0:i_f]\n",
    "        y_tst[:L-i_f] = Ydata[i_f:]\n",
    "        y_tst[L-i_f:] = Ydata[:i_0]\n",
    "\n",
    "    return X_tr, X_tst, y_tr, y_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_decoder(XData,yData,pars=[],trials = 15):\n",
    "    trained_models = []\n",
    "    MSE = []\n",
    "    R2 = []\n",
    "    predictions = []\n",
    "    \n",
    "    T = round(len(yData)*0.25)\n",
    "    L = XData.shape[0]\n",
    "    for i in range(trials):\n",
    "\n",
    "        X_train, X_test, y_train, y_test = split_dataset(XData,yData,trials,i,T)\n",
    "        \n",
    "        if len(pars)>0:   \n",
    "            model_tf = create_custom_model(X_train.shape[1], 1, [100,100], name='model_tf',activation = ['relu','tanh'])\n",
    "            model = model_tf()\n",
    "            model.fit(X_train,y_train,batch_size=pars[0],epochs=pars[1],verbose=pars[2],validation_data=(X_test, y_test),callbacks=[pars[3]])\n",
    "        else:\n",
    "            model = linear_model.LinearRegression()\n",
    "            model.fit(X_train,y_train)\n",
    "            \n",
    "#         trained_models.append(model)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        predictions.append([y_pred,y_test,X_test])\n",
    "        R2.append(sk.metrics.r2_score(y_test,y_pred))\n",
    "        MSE.append(sk.metrics.mean_squared_error(y_test,y_pred,squared=False))\n",
    "                \n",
    "    return trained_models, MSE, R2, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_depth_decoder(z_depth,XData,yData,pars=[],trials = 5, trials_neuron = 1,nonPCA = False):\n",
    "    \n",
    "    T = round(len(yData)*0.25)\n",
    "    L = XData.shape[0]\n",
    "\n",
    "    pca_layers_zscore = []\n",
    "    z_values = np.unique(z_depth)\n",
    "\n",
    "    minimal_neuron_count = min([len(np.where(z_depth == z_values[layer])[0]) for layer in range(len(z_values))]) #number of neurons in the layer which has the least number of neurons\n",
    "    minimal_neuron_count = round(minimal_neuron_count*0.9) # grab 90% of this number\n",
    "    \n",
    "    trained_models = []\n",
    "    MSE = np.zeros((len(z_values),trials_neuron,trials))\n",
    "    R2 = np.zeros((len(z_values),trials_neuron,trials))\n",
    "    predictions = []\n",
    "    \n",
    "    for layer in range(len(z_values)):\n",
    "\n",
    "#         trained_models.append([])\n",
    "        predictions.append([]) \n",
    "\n",
    "        for i in range(trials_neuron):\n",
    "\n",
    "            pca_layer_model = PCA(n_components=500)\n",
    "\n",
    "            index = np.where(z_depth == z_values[layer])[0]\n",
    "            random.shuffle(index)\n",
    "            pca_layers_zscore.append(pca_model.fit_transform(XData[index[:minimal_neuron_count]].T))\n",
    "\n",
    "#             trained_models[-1].append([])\n",
    "            predictions[-1].append([])\n",
    "\n",
    "            for j in range(trials):\n",
    "\n",
    "                X_train, X_test, y_train, y_test = split_dataset(pca_layers_zscore[-1],yData,trials,j,T)\n",
    "\n",
    "                if len(pars)>0:   \n",
    "                    model_tf = create_custom_model(X_train.shape[1], 1, [100,100], name='model_tf',activation = ['relu','tanh'])\n",
    "                    model = model_tf()\n",
    "                    model.fit(X_train,y_train,batch_size=pars[0],epochs=pars[1],verbose=pars[2],validation_data=(X_test, y_test),callbacks=[pars[3]])\n",
    "                else:\n",
    "                    model = linear_model.LinearRegression()\n",
    "                    model.fit(X_train,y_train)\n",
    "\n",
    "#                 trained_models[-1].append(model)\n",
    "\n",
    "                y_pred = model.predict(X_test)\n",
    "                predictions[-1].append([y_pred,y_test,X_test])\n",
    "                R2[layer,i,j] = sk.metrics.r2_score(y_test,y_pred)\n",
    "                MSE[layer,i,j] = sk.metrics.mean_squared_error(y_test,y_pred,squared=False)\n",
    "                \n",
    "                print(layer,i,j)\n",
    "                \n",
    "    return trained_models, MSE, R2, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_list(data2save,name,dir2save=r'C:\\Users\\Facundo\\Desktop\\CONICET\\Doctorado\\Cursos\\Neuro Match Academy\\Project Continuation\\data_stimuli'):\n",
    "    # open file in write mode\n",
    "    with open(dir2save+dir2save[2]+name+'.txt', 'w') as fp:\n",
    "        for item in data2save:\n",
    "            # write each item on a new line\n",
    "            fp.write(\"%s\\n\" % item)\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 15\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4) #if there is no improvement in validation loss function for \"#patience\" epochs, then training stops\n",
    "pars = [batch_size,n_epochs,0,[callback]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pupil Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_models_ffnn, MSE_ffnn, R2_ffnn, predictions_ffnn = general_decoder(pca_zscore,pupilArea,pars,trials = 15)\n",
    "trained_models_linear, MSE_linear, R2_linear, predictions_linear = general_decoder(pca_zscore,pupilArea,[],trials = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "save_list(MSE_ffnn,rat+'_full_MSE_ffnn_PupArea')\n",
    "save_list(R2_ffnn,rat+'_full_R2_ffnn_PupArea')\n",
    "save_list(MSE_linear,rat+'_full_MSE_linear_PupArea')\n",
    "save_list(R2_linear,rat+'_full_R2_linear_PupArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 1\n",
      "0 0 2\n",
      "0 0 3\n",
      "0 0 4\n",
      "1 0 0\n",
      "1 0 1\n",
      "1 0 2\n",
      "1 0 3\n",
      "1 0 4\n",
      "2 0 0\n",
      "2 0 1\n",
      "2 0 2\n",
      "2 0 3\n",
      "2 0 4\n",
      "3 0 0\n",
      "3 0 1\n",
      "3 0 2\n",
      "3 0 3\n",
      "3 0 4\n",
      "4 0 0\n",
      "4 0 1\n",
      "4 0 2\n",
      "4 0 3\n",
      "4 0 4\n",
      "5 0 0\n",
      "5 0 1\n",
      "5 0 2\n",
      "5 0 3\n",
      "5 0 4\n",
      "6 0 0\n",
      "6 0 1\n",
      "6 0 2\n",
      "6 0 3\n",
      "6 0 4\n",
      "7 0 0\n",
      "7 0 1\n",
      "7 0 2\n",
      "7 0 3\n",
      "7 0 4\n",
      "8 0 0\n",
      "8 0 1\n",
      "8 0 2\n",
      "8 0 3\n",
      "8 0 4\n",
      "9 0 0\n",
      "9 0 1\n",
      "9 0 2\n",
      "9 0 3\n",
      "9 0 4\n",
      "10 0 0\n",
      "10 0 1\n",
      "10 0 2\n",
      "10 0 3\n",
      "10 0 4\n",
      "0 0 0\n",
      "0 0 1\n",
      "0 0 2\n",
      "0 0 3\n",
      "0 0 4\n",
      "1 0 0\n",
      "1 0 1\n",
      "1 0 2\n",
      "1 0 3\n",
      "1 0 4\n",
      "2 0 0\n",
      "2 0 1\n",
      "2 0 2\n",
      "2 0 3\n",
      "2 0 4\n",
      "3 0 0\n",
      "3 0 1\n",
      "3 0 2\n",
      "3 0 3\n",
      "3 0 4\n",
      "4 0 0\n",
      "4 0 1\n",
      "4 0 2\n",
      "4 0 3\n",
      "4 0 4\n",
      "5 0 0\n",
      "5 0 1\n",
      "5 0 2\n",
      "5 0 3\n",
      "5 0 4\n",
      "6 0 0\n",
      "6 0 1\n",
      "6 0 2\n",
      "6 0 3\n",
      "6 0 4\n",
      "7 0 0\n",
      "7 0 1\n",
      "7 0 2\n",
      "7 0 3\n",
      "7 0 4\n",
      "8 0 0\n",
      "8 0 1\n",
      "8 0 2\n",
      "8 0 3\n",
      "8 0 4\n",
      "9 0 0\n",
      "9 0 1\n",
      "9 0 2\n",
      "9 0 3\n",
      "9 0 4\n",
      "10 0 0\n",
      "10 0 1\n",
      "10 0 2\n",
      "10 0 3\n",
      "10 0 4\n"
     ]
    }
   ],
   "source": [
    "trained_models_ffnnDEPTH, MSE_ffnnDEPTH, R2_ffnnDEPTH, predictions_ffnnDEPTH = general_depth_decoder(xyz.T[-1],Z,pupilArea,pars)\n",
    "trained_models_linearDEPTH, MSE_linearDEPTH, R2_linearDEPTH, predictions_linearDEPTH = general_depth_decoder(xyz.T[-1],Z,pupilArea,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "save_list(list([list(x[0]) for x in MSE_ffnnDEPTH]),rat+'_MSE_ffnnDEPTH_PupArea')\n",
    "save_list(list([list(x[0]) for x in R2_ffnnDEPTH]),rat+'_R2_ffnnDEPTH_PupArea')\n",
    "save_list(list([list(x[0]) for x in MSE_linearDEPTH]),rat+'_MSE_linearDEPTH_PupArea')\n",
    "save_list(list([list(x[0]) for x in R2_linearDEPTH]),rat+'_R2_linearDEPTH_PupArea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_full_neurons(MSE_ffnn,MSE_linear,R2_ffnn,R2_linear):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(15,10))\n",
    "    pass\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    ax = sns.boxplot(data=[MSE_ffnn,MSE_linear])\n",
    "    ax = sns.stripplot(data=[MSE_ffnn,MSE_linear],color='orange')\n",
    "    ax.set_xticks([0,1])\n",
    "    ax.set_xticklabels(['FFNN','Linear'])#, minor=False, rotation=45)\n",
    "    plt.ylabel('MSE')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    ax = sns.boxplot(data=[R2_ffnn,R2_linear])\n",
    "    ax = sns.stripplot(data=[R2_ffnn,R2_linear],color='orange')\n",
    "    ax.set_xticks([0,1])\n",
    "    ax.set_xticklabels(['FFNN','Linear'])#, minor=False, rotation=45)\n",
    "    plt.ylabel('$R^2$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_neurons(MSE_ffnn,MSE_linear,R2_ffnn,R2_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_depth(MSE_ffnnDEPTH,R2_ffnnDEPTH,MSE_linearDEPTH,R2_linearDEPTH):\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(20,8))\n",
    "    pass\n",
    "\n",
    "    DATA_MSEffnn = []\n",
    "    for i in range(len(MSE_ffnnDEPTH)):\n",
    "        DATA_MSEffnn.append([x for K in MSE_ffnnDEPTH[i] for x in K])\n",
    "\n",
    "    DATA_R2ffnn = []\n",
    "    for i in range(len(R2_ffnnDEPTH)):\n",
    "        DATA_R2ffnn.append([x for K in R2_ffnnDEPTH[i] for x in K])\n",
    "\n",
    "    DATA_MSElinear = []\n",
    "    for i in range(len(MSE_linearDEPTH)):\n",
    "        DATA_MSElinear.append([x for K in MSE_linearDEPTH[i] for x in K])\n",
    "\n",
    "    DATA_R2linear = []\n",
    "    for i in range(len(R2_linearDEPTH)):\n",
    "        DATA_R2linear.append([x for K in R2_linearDEPTH[i] for x in K])\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    ax = sns.boxplot(data=DATA_MSEffnn)\n",
    "    ax = sns.stripplot(data=DATA_MSEffnn,color='orange')\n",
    "    ax.set_xticks([x for x in range(len(R2_ffnnDEPTH))])\n",
    "    ax.set_xticklabels(list(range(1,len(R2_ffnnDEPTH)+1)))\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Layers')\n",
    "    plt.title('Feedforward neural network')\n",
    "    # plt.ylim([140,400])\n",
    "\n",
    "    plt.subplot(2,2,2)\n",
    "    ax = sns.boxplot(data=DATA_MSElinear)\n",
    "    ax = sns.stripplot(data=DATA_MSElinear,color='orange')\n",
    "    ax.set_xticks([x for x in range(len(R2_ffnnDEPTH))])\n",
    "    ax.set_xticklabels(list(range(1,len(R2_ffnnDEPTH)+1)))\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Layers')\n",
    "    plt.title('Linear decoder')\n",
    "    # plt.ylim([140,400])\n",
    "\n",
    "    plt.subplot(2,2,3)\n",
    "    ax = sns.boxplot(data=DATA_R2ffnn)\n",
    "    ax = sns.stripplot(data=DATA_R2ffnn,color='orange')\n",
    "    ax.set_xticks([x for x in range(len(R2_ffnnDEPTH))])\n",
    "    ax.set_xticklabels(list(range(1,len(R2_ffnnDEPTH)+1)))\n",
    "    plt.ylabel('$R^2$')\n",
    "    plt.xlabel('Layers')\n",
    "    plt.title('Feedforward neural network')\n",
    "    # plt.ylim([0,1])\n",
    "\n",
    "    plt.subplot(2,2,4)\n",
    "    ax = sns.boxplot(data=DATA_R2linear)\n",
    "    ax = sns.stripplot(data=DATA_R2linear,color='orange')\n",
    "    ax.set_xticks([x for x in range(len(R2_ffnnDEPTH))])\n",
    "    ax.set_xticklabels(list(range(1,len(R2_ffnnDEPTH)+1)))\n",
    "    plt.ylabel('$R^2$')\n",
    "    plt.xlabel('Layers')\n",
    "    plt.title('Linear decoder')\n",
    "    # plt.ylim([0,1])\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_depth(MSE_ffnnDEPTH,R2_ffnnDEPTH,MSE_linearDEPTH,R2_linearDEPTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPEEDtrained_models_ffnn, SPEEDMSE_ffnn, SPEEDR2_ffnn, SPEEDpredictions_ffnn = general_decoder(pca_zscore,runSpeed,pars,trials = 15)\n",
    "SPEEDtrained_models_linear, SPEEDMSE_linear, SPEEDR2_linear, SPEEDpredictions_linear = general_decoder(pca_zscore,runSpeed,[],trials = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "save_list(SPEEDMSE_ffnn,rat+'_full_MSE_ffnn_Speed')\n",
    "save_list(SPEEDR2_ffnn,rat+'_full_R2_ffnn_Speed')\n",
    "save_list(SPEEDMSE_linear,rat+'_full_MSE_linear_Speed')\n",
    "save_list(SPEEDR2_linear,rat+'_full_R2_linear_Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_full_neurons(SPEEDMSE_ffnn,SPEEDR2_ffnn,SPEEDMSE_linear,SPEEDR2_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 1\n",
      "0 0 2\n",
      "0 0 3\n",
      "0 0 4\n",
      "1 0 0\n",
      "1 0 1\n",
      "1 0 2\n",
      "1 0 3\n",
      "1 0 4\n",
      "2 0 0\n"
     ]
    }
   ],
   "source": [
    "SPEEDtrained_models_ffnnDEPTH, SPEEDMSE_ffnnDEPTH, SPEEDR2_ffnnDEPTH, SPEEDpredictions_ffnnDEPTH = general_depth_decoder(xyz.T[-1],Z,runSpeed,pars)\n",
    "SPEEDtrained_models_linearDEPTH, SPEEDMSE_linearDEPTH, SPEEDR2_linearDEPTH, SPEEDpredictions_linearDEPTH = general_depth_decoder(xyz.T[-1],Z,runSpeed,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_list(list([list(x[0]) for x in SPEEDMSE_ffnnDEPTH]),rat+'_MSE_ffnnDEPTH_Speed')\n",
    "save_list(list([list(x[0]) for x in SPEEDR2_ffnnDEPTH]),rat+'_R2_ffnnDEPTH_Speed')\n",
    "save_list(list([list(x[0]) for x in SPEEDMSE_linearDEPTH]),rat+'_MSE_linearDEPTH_Speed')\n",
    "save_list(list([list(x[0]) for x in SPEEDR2_linearDEPTH]),rat+'_R2_linearDEPTH_Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_depth(SPEEDMSE_ffnnDEPTH,SPEEDR2_ffnnDEPTH,SPEEDMSE_linearDEPTH,SPEEDR2_linearDEPTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### runAngle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNANGtrained_models_ffnn, RUNANGMSE_ffnn, RUNANGR2_ffnn, RUNANGpredictions_ffnn = general_decoder(pca_zscore,pupilArea,pars,trials = 15)\n",
    "# RUNANGtrained_models_linear, RUNANGMSE_linear, RUNANGR2_linear, RUNANGpredictions_linear = general_decoder(pca_zscore,pupilArea,[],trials = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNANGtrained_models_ffnn, RUNANGMSE_ffnn, RUNANGR2_ffnn, RUNANGpredictions_ffnn = general_depth_decoder(xyz.T[-1],Z,runAngle,pars)\n",
    "# RUNANGtrained_models_linear, RUNANGMSE_linear, RUNANGR2_linear, RUNANGpredictions_linear = general_depth_decoder(xyz.T[-1],Z,runAngle,[])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
